stage0: &stage0 1000
stage1: &stage1 3000
stage2: &stage2 4000

Experiment:
    name: main_loop
    class_name: cognitive_processes.main_loop.MainLoop
    new_executor: True
    threads: 2
    parameters: 
        iterations: 10000
        trials: 20
        subgoals: False
        softmax_selection: True
        softmax_temperature: 0.3
        kill_on_finish: True
Control:
    id: ltm_simulator
    control_topic: /main_loop/control
    control_msg: cognitive_processes_interfaces.msg.ControlMsg
    episodes_topic: /main_loop/episodes
    episodes_msg: cognitive_processes_interfaces.msg.Episode
    executed_policy_service: /emdb/simulator/executed_policy
    executed_policy_msg: cognitive_node_interfaces.srv.Policy
    world_reset_service: /emdb/simulator/world_reset
    world_reset_msg: cognitive_processes_interfaces.srv.WorldReset
LTM:
    Files:
        -
            id: goodness
            class: core.file.FileGoodness
            file: goodness.txt
        -
            id: pnodes_success
            class: core.file.FilePNodesSuccess
            file: pnodes_success.txt
        -
            id: pnodes_content
            class: core.file.FilePNodesContent
            file: pnodes_content.txt
        -
            id: pnodes_content_last_iteration
            class: core.file.FileLastIterationPNodesContent
            file: pnodes_content_last_ite.txt
        -
            id: goals_content
            class: core.file.FileGoalsContent
            file: goals_content.txt
        -
            id: goals_content_last_iteration
            class: core.file.FileLastIterationGoalsContent
            file: goals_content_last_ite.txt
        -
            id: trials
            class: core.file.FileTrialsSuccess
            file: trials.txt
        -
            id: neighbors
            class: core.file.FileNeighbors
            file: neighbors.txt
        -
            id: neighbors_full
            class: core.file.FileNeighborsFull
            file: neighbors_full.txt
    Connectors:
        -
            data: Space
            default_class: cognitive_nodes.space.ANNSpace
        -
            data: Perception
            default_class: cognitive_nodes.perception.Perception
        -
            data: PNode
            default_class: cognitive_nodes.pnode.PNode
        -
            data: CNode
            default_class: cognitive_nodes.cnode.CNode
        -
            data: Goal
            default_class: cognitive_nodes.goal.GoalLearnedSpace
        -
            data: WorldModel
            default_class: cognitive_nodes.world_model.WorldModel
        -
            data: Policy
            default_class: cognitive_nodes.policy.PolicyBlocking

    Nodes:
        Perception:
            -
                name: button_light
                class_name: cognitive_nodes.perception.FruitShopPerception
                parameters:
                    default_msg: std_msgs.msg.Bool
                    default_topic: /emdb/simulator/sensor/button_light
            -
                name: fruit_in_left_hand
                class_name: cognitive_nodes.perception.FruitShopPerception
                parameters:
                    default_msg: std_msgs.msg.Bool
                    default_topic: /emdb/simulator/sensor/fruit_in_left_hand
            -
                name: fruit_in_right_hand
                class_name: cognitive_nodes.perception.FruitShopPerception
                parameters:
                    default_msg: std_msgs.msg.Bool
                    default_topic: /emdb/simulator/sensor/fruit_in_right_hand
            -
                name: fruits
                class_name: cognitive_nodes.perception.FruitShopPerception
                parameters:
                    default_msg: simulators_interfaces.msg.FruitListMsg
                    default_topic: /emdb/simulator/sensor/fruits
                    normalize_data:
                        distance_min: 0.2
                        distance_max: 1.9
                        angle_min: -1.4
                        angle_max: 1.4
                        diameter_min: 0.0
                        diameter_max: 0.15
                        dim_min: 0.03
                        dim_max: 0.1
            -
                name: scales
                class_name: cognitive_nodes.perception.FruitShopPerception
                parameters:
                    default_msg: simulators_interfaces.msg.ScaleListMsg
                    default_topic: /emdb/simulator/sensor/scales
                    normalize_data:
                        distance_min: 0.2
                        distance_max: 1.9
                        angle_min: -1.4
                        angle_max: 1.4
                        diameter_min: 0.0
                        diameter_max: 0.15
                        n_states: 3
        WorldModel:
            -
                name: FRUIT_SHOP
                class_name: cognitive_nodes.world_model.WorldModel
        Need: 
            -
                name: classify_fruit_need
                class_name: cognitive_nodes.need.Need
                parameters:
                    weight: 1.0
                    drive_id: 'classify_fruit_drive'
                    need_type: 'Operational'
            -
                name: place_fruit_need
                class_name: cognitive_nodes.need.Need
                parameters:
                    weight: 1.0
                    drive_id: 'place_fruit_drive'
                    need_type: 'Other'
            - 
                name: llm_exploration_need
                class_name: cognitive_nodes.need.Need
                parameters:
                    weight: 0.1
                    drive_id: 'llm_exploration_drive'
                    need_type: 'Cognitive'
            - 
                name: effectance_need
                class_name: cognitive_nodes.need.Need
                parameters:
                    weight: 0.25
                    drive_id: 'effectance_drive'
                    need_type: 'Cognitive'
            - 
                name: external_effects_need
                class_name: cognitive_nodes.need.Need
                parameters:
                    weight: 0.3
                    drive_id: 'external_effects_drive'
                    need_type: 'Cognitive'
            - 
                name: prospection_need
                class_name: cognitive_nodes.need.Need
                parameters:
                    weight: 1.0
                    drive_id: 'prospection_drive'
                    need_type: 'Cognitive'
        Drive:
            -
                name: classify_fruit_drive
                class_name: cognitive_nodes.drive.DriveExponential
                parameters:
                    input_topic: /emdb/simulator/sensor/classify_fruit
                    input_msg: std_msgs.msg.Float32
                    min_eval: 0.8 
                    neighbors: [{"name": "classify_fruit_need", "node_type": "Need"}]
            -
                name: place_fruit_drive
                class_name: cognitive_nodes.drive.DriveExponential
                parameters:
                    input_topic: /emdb/simulator/sensor/place_fruit
                    input_msg: std_msgs.msg.Float32
                    min_eval: 0.8 
                    neighbors: [{"name": "place_fruit_need", "node_type": "Need"}]

            -
                name: llm_exploration_drive
                class_name: cognitive_nodes.llm_exploration.DriveLLMExploration
                parameters:
                    neighbors: [{"name": "llm_exploration_need", "node_type": "Need"}]
            -
                name: effectance_drive
                class_name: cognitive_nodes.effectance.DriveEffectanceInternal
                parameters:
                    ltm_id: ltm_0
                    min_confidence: 0.84
                    limit_depth: True
                    neighbors: [{"name": "effectance_need", "node_type": "Need"}]
            -
                name: external_effects_drive
                class_name: cognitive_nodes.effectance.DriveEffectanceExternal
                parameters:
                    episodes_topic: /main_loop/episodes
                    episodes_msg: cognitive_processes_interfaces.msg.Episode
                    neighbors: [{"name": "external_effects_need", "node_type": "Need"}]
            -
                name: prospection_drive
                class_name: cognitive_nodes.prospection.ProspectionDrive
                parameters:
                    ltm_id: ltm_0
                    min_pnode_rate: 0.85
                    min_goal_rate: 0.95
                    neighbors: [{"name": "prospection_need", "node_type": "Need"}]
        Goal:
            -
                name: llm_exploration_goal
                class_name: cognitive_nodes.goal.GoalMotiven
                parameters:
                    neighbors: [{"name": "llm_exploration_drive", "node_type": "Drive"}]
            -
                name: effectance_goal
                class_name: dummy_nodes.dummy_goal.GoalDummy
                parameters:
                    neighbors: [{"name": "effectance_drive", "node_type": "Drive"}]
            -
                name: external_effects_goal
                class_name: dummy_nodes.dummy_goal.GoalDummy
                parameters:
                    neighbors: [{"name": "external_effects_drive", "node_type": "Drive"}]
            -
                name: prospection_goal
                class_name: dummy_nodes.dummy_goal.GoalDummy
                parameters:
                    neighbors: [{"name": "prospection_drive", "node_type": "Drive"}]
        PNode:
            -
                name: llm_exploration_pnode
                class_name: dummy_nodes.dummy_pnodes.ActivatedDummyPNode
                parameters:
                    space_class: cognitive_nodes.space.ActivatedDummySpace
            -
                name: effectance_pnode
                class_name: dummy_nodes.dummy_pnodes.ActivatedDummyPNode
                parameters:
                    space_class: cognitive_nodes.space.ActivatedDummySpace
            -
                name: external_effects_pnode
                class_name: dummy_nodes.dummy_pnodes.ActivatedDummyPNode
                parameters:
                    space_class: cognitive_nodes.space.ActivatedDummySpace
            -
                name: prospection_pnode
                class_name: dummy_nodes.dummy_pnodes.ActivatedDummyPNode
                parameters:
                    space_class: cognitive_nodes.space.ActivatedDummySpace
        CNode:
            -
                name: llm_exploration_cnode
                class_name: cognitive_nodes.cnode.CNode
                parameters:
                    neighbors: [{"name": "llm_exploration_goal", "node_type": "Goal"}, {"name": "FRUIT_SHOP", "node_type": "WorldModel"}, {"name": "llm_exploration_pnode", "node_type": "PNode"}]
            -
                name: effectance_cnode
                class_name: cognitive_nodes.cnode.CNode
                parameters:
                    neighbors: [{"name": "effectance_goal", "node_type": "Goal"}, {"name": "FRUIT_SHOP", "node_type": "WorldModel"}, {"name": "effectance_pnode", "node_type": "PNode"}]
            -
                name: external_effects_cnode
                class_name: cognitive_nodes.cnode.CNode
                parameters:
                    neighbors: [{"name": "external_effects_goal", "node_type": "Goal"}, {"name": "FRUIT_SHOP", "node_type": "WorldModel"}, {"name": "external_effects_pnode", "node_type": "PNode"}]
            -
                name: prospection_cnode
                class_name: cognitive_nodes.cnode.CNode
                parameters:
                    neighbors: [{"name": "prospection_goal", "node_type": "Goal"}, {"name": "FRUIT_SHOP", "node_type": "WorldModel"}, {"name": "prospection_pnode", "node_type": "PNode"}]

        Policy:
            -
                name: pick_fruit
                class_name: cognitive_nodes.policy.PolicyBlocking
                parameters:
                    service_msg: cognitive_node_interfaces.srv.Policy
                    service_name: /emdb/simulator/executed_policy
            -
                name: place_fruit
                class_name: cognitive_nodes.policy.PolicyBlocking
                parameters:
                    service_msg: cognitive_node_interfaces.srv.Policy
                    service_name: /emdb/simulator/executed_policy
            -
                name: change_hands
                class_name: cognitive_nodes.policy.PolicyBlocking
                parameters:
                    service_msg: cognitive_node_interfaces.srv.Policy
                    service_name: /emdb/simulator/executed_policy
            -
                name: test_fruit
                class_name: cognitive_nodes.policy.PolicyBlocking
                parameters:
                    service_msg: cognitive_node_interfaces.srv.Policy
                    service_name: /emdb/simulator/executed_policy  
            -
                name: accept_fruit
                class_name: cognitive_nodes.policy.PolicyBlocking
                parameters:
                    service_msg: cognitive_node_interfaces.srv.Policy
                    service_name: /emdb/simulator/executed_policy   
            -
                name: discard_fruit
                class_name: cognitive_nodes.policy.PolicyBlocking
                parameters:
                    service_msg: cognitive_node_interfaces.srv.Policy
                    service_name: /emdb/simulator/executed_policy  
            -
                name: press_button
                class_name: cognitive_nodes.policy.PolicyBlocking
                parameters:
                    service_msg: cognitive_node_interfaces.srv.Policy
                    service_name: /emdb/simulator/executed_policy  
            -
                name: ask_nicely
                class_name: cognitive_nodes.policy.PolicyBlocking
                parameters:
                    service_msg: cognitive_node_interfaces.srv.Policy
                    service_name: /emdb/simulator/executed_policy
            -
                name: llm_exploration_policy
                class_name: cognitive_nodes.llm_exploration.PolicyLLMExplorationFruitShop
                parameters:
                    exclude_list: ["effectance_policy", "external_effect_policy", "prospection_policy"]
                    neighbors: [{"name": "llm_exploration_cnode", "node_type": "CNode"}]
                    model: "phi4:14b"
                    client_host: "http://10.113.36.20:11434"
                    temperature: 0.1
                    num_predict: 8
                    exp_stages: [*stage0,*stage1,*stage2]
                    initial_prompts:
                    -
                        role: "system"
                        content: |
                            A cognitive architecture is controlling a robot with two arms. You have to guide the cognitive architecture in the first steps to achieve the goal. The goal is: cause effects in the enviroment.
                            Effect means that a boolean sensor change its value from 0 to 1.
                            <Perceptions>
                            - Fruits: 
                                - Distance: How far the closest fruit is from the robot (0 to 1, 0 is closest). Distance = 1 means there are no fruits.
                                - Angle: Where the fruit is (0 to 1, less than 0.5 is left, more than 0.5 is right). Angle = 1 means there are no fruits.
                                - Dim_max: Size of the fruit (0 to 1, larger is closer to 1). Dim_max = 1 means there are no fruits.
                            - Scales:
                                - Distance: How far the scale is from the robot (0 to 1, 0 is closest).
                                - Angle: Where the scale is (0 to 1, less than 0.5 is left, more than 0.5 is right).
                                - State: 0 if the fruit is not classified, 0.5 if the fruit’s weight is correct, 0.98 if the fruit’s weight is incorrect.
                                - Active: 1 if a fruit is on the scale, 0 if not.
                            - Fruit_in_left_hand: 1 if a fruit is in the left arm, 0 if not.
                            - Fruit_in_right_hand: 1 if a fruit is in the right arm, 0 if not.
                            - Button_light: 1 if the button light is on, 0 if off. 
                            </Perceptions>

                            <Actions> 
                            - pick_fruit: Grab the closest fruit if it is close (right arm for right side, left arm for left side). 
                            - change_hands: Move a fruit to the other arm if it is already grasped if its size (Dim_max) is less than 0.78.
                            - place_fruit: Put a fruit on the table center to change its side if the fruit is already grasped.
                            - test_fruit: Put a fruit on the scale to check its weight if the fruit is grasped in the same side of the scale.
                            - discard_fruit: Put a fruit with incorrect weight (Scales State = 0.98) in the discarded fruit box. 
                            - accept_fruit: Put a fruit with correct weight (Scales State = 0.5) in the accepted fruit box. 
                            - press_button: Turn the button light on or off.
                            - ask_nicely: Ask the experimenter for more fruits, if there are none. 
                            </Actions>

                            You will receive several messages, ordered chronologically, in YAML format with the last episodes (old_perception, policy_executed, current_perception, goal_reached). In the first step, you will only have avaliable the current_perception.
                            Try to change all the boolean sensors from 0 to 1.
                            Try to use actions other than those that reached the goal in the previous episodes, in order to try to discover new effects.

                            Reply only with one action name (pick_fruit, change_hands, place_fruit, test_fruit, accept_fruit, discard_fruit, press_button, ask_nicely), with no explanations or extra words.
                    -   
                        role: "system"
                        content: |
                            A cognitive architecture is controlling a robot with two arms. You have to guide the cognitive architecture in the first steps to achieve the goal. The goal is: place the fruit in the table center.
                            <Perceptions>
                            - Fruits: 
                                - Distance: How far the closest fruit is from the robot (0 to 1, 0 is closest). Distance = 1 means there are no fruits.
                                - Angle: Where the fruit is (0 to 1, less than 0.5 is left, more than 0.5 is right). Angle = 1 means there are no fruits.
                                - Dim_max: Size of the fruit (0 to 1, larger is closer to 1). Dim_max = 1 means there are no fruits.
                            - Scales:
                                - Distance: How far the scale is from the robot (0 to 1, 0 is closest).
                                - Angle: Where the scale is (0 to 1, less than 0.5 is left, more than 0.5 is right).
                                - State: 0 if the fruit is not classified, 0.5 if the fruit’s weight is correct, 0.98 if the fruit’s weight is incorrect.
                                - Active: 1 if a fruit is on the scale, 0 if not.
                            - Fruit_in_left_hand: 1 if a fruit is in the left arm, 0 if not.
                            - Fruit_in_right_hand: 1 if a fruit is in the right arm, 0 if not.
                            - Button_light: 1 if the button light is on, 0 if off. 
                            </Perceptions>

                            <Actions> 
                            - pick_fruit: Grab the closest fruit if it is close (right arm for right side, left arm for left side). 
                            - change_hands: Move a fruit to the other arm if it is already grasped if its size (Dim_max) is less than 0.78.
                            - place_fruit: Put a fruit on the table center to change its side if the fruit is already grasped.
                            - test_fruit: Put a fruit on the scale to check its weight if the fruit is grasped in the same side of the scale.
                            - discard_fruit: Put a fruit with incorrect weight (Scales State = 0.98) in the discarded fruit box. 
                            - accept_fruit: Put a fruit with correct weight (Scales State = 0.5) in the accepted fruit box.
                            - press_button: Turn the button light on or off.
                            - ask_nicely: Ask the experimenter for more fruits, if there are none. 
                            </Actions>

                            You will receive several messages, ordered chronologically, in YAML format with the last episodes (old_perception, policy_executed, current_perception, goal_reached). In the first step, you will only have avaliable the current_perception.
                            If an action did not change the perceptions in the last episode received (old_perception == current_perception), do not repeat it in the current step.
                            Reply only with one action name (pick_fruit, change_hands, place_fruit, test_fruit, accept_fruit, discard_fruit, press_button, ask_nicely), with no explanations, extra words or extra elements.
                    -
                        role: "system"
                        content: |
                            A cognitive architecture is controlling a robot with two arms. You have to guide the cognitive architecture in the first steps to achieve the goal. The goal is: cause effects in the enviroment.
                            Effect means that a boolean sensor change its value from 0 to 1.
                            <Perceptions>
                            - Fruits: 
                                - Distance: How far the closest fruit is from the robot (0 to 1, 0 is closest). Distance = 1 means there are no fruits.
                                - Angle: Where the fruit is (0 to 1, less than 0.5 is left, more than 0.5 is right). Angle = 1 means there are no fruits.
                                - Dim_max: Size of the fruit (0 to 1, larger is closer to 1). Dim_max = 1 means there are no fruits.
                            - Scales:
                                - Distance: How far the scale is from the robot (0 to 1, 0 is closest).
                                - Angle: Where the scale is (0 to 1, less than 0.5 is left, more than 0.5 is right).
                                - State: 0 if the fruit is not classified, 0.5 if the fruit’s weight is correct, 0.98 if the fruit’s weight is incorrect.
                                - Active: 1 if a fruit is on the scale, 0 if not.
                            - Fruit_in_left_hand: 1 if a fruit is in the left arm, 0 if not.
                            - Fruit_in_right_hand: 1 if a fruit is in the right arm, 0 if not.
                            - Button_light: 1 if the button light is on, 0 if off. 
                            </Perceptions>

                            <Actions> 
                            - pick_fruit: Grab the closest fruit if it is close (right arm for right side, left arm for left side). 
                            - change_hands: Move a fruit to the other arm if it is already grasped if its size (Dim_max) is less than 0.78.
                            - place_fruit: Put a fruit on the table center to change its side if the fruit is already grasped.
                            - test_fruit: Put a fruit on the scale to check its weight if the fruit is grasped in the same side of the scale.
                            - discard_fruit: Put a fruit with incorrect weight (Scales State = 0.98) in the discarded fruit box. 
                            - accept_fruit: Put a fruit with correct weight (Scales State = 0.5) in the accepted fruit box. 
                            - press_button: Turn the button light on or off.
                            - ask_nicely: Ask the experimenter for more fruits, if there are none. 
                            </Actions>

                            You will receive several messages, ordered chronologically, in YAML format with the last episodes (old_perception, policy_executed, current_perception, goal_reached). In the first step, you will only have avaliable the current_perception.
                            Try to change all the boolean sensors from 0 to 1.
                            Try to use actions other than those that reached the goal in the previous episodes, in order to try to discover new effects.

                            Reply only with one action name (pick_fruit, change_hands, place_fruit, test_fruit, accept_fruit, discard_fruit, press_button, ask_nicely), with no explanations or extra words.
                    -
                        role: "system"
                        content: |
                            A cognitive architecture is controlling a robot with two arms. You have to guide the cognitive architecture in the first steps to achieve the goal. The goal is: classify fruits by its weight.
                            <Perceptions>
                            - Fruits: 
                                - Distance: How far the closest fruit is from the robot (0 to 1, 0 is closest). Distance = 1 means there are no fruits.
                                - Angle: Where the fruit is (0 to 1, less than 0.5 is left, more than 0.5 is right). Angle = 1 means there are no fruits.
                                - Dim_max: Size of the fruit (0 to 1, larger is closer to 1). Dim_max = 1 means there are no fruits.
                            - Scales:
                                - Distance: How far the scale is from the robot (0 to 1, 0 is closest).
                                - Angle: Where the scale is (0 to 1, less than 0.5 is left, more than 0.5 is right).
                                - State: 0 if the fruit is not classified, 0.5 if the fruit’s weight is correct, 0.98 if the fruit’s weight is incorrect.
                                - Active: 1 if a fruit is on the scale, 0 if not.
                            - Fruit_in_left_hand: 1 if a fruit is in the left arm, 0 if not.
                            - Fruit_in_right_hand: 1 if a fruit is in the right arm, 0 if not.
                            - Button_light: 1 if the button light is on, 0 if off. 
                            </Perceptions>

                            <Actions> 
                            - pick_fruit: Grab the closest fruit if it is close (right arm for right side, left arm for left side). 
                            - change_hands: Move a fruit to the other arm if it is already grasped if its size (Dim_max) is less than 0.78.
                            - place_fruit: Put a fruit on the table center to change its side if the fruit is already grasped.
                            - test_fruit: Put a fruit on the scale to check its weight if the fruit is grasped in the same side of the scale.
                            - discard_fruit: Put a fruit with incorrect weight (Scales State = 0.98) in the discarded fruit box. 
                            - accept_fruit: Put a fruit with correct weight (Scales State = 0.5) in the accepted fruit box. 
                            - press_button: Turn the button light on or off.
                            - ask_nicely: Ask the experimenter for more fruits, if there are none. 
                            </Actions>

                            You will receive several messages, ordered chronologically, in YAML format with the last episodes (old_perception, policy_executed, current_perception, goal_reached). In the first step, you will only have avaliable the current_perception.
                            If an action did not change the perceptions in the last episode received (old_perception == current_perception), do not repeat it in the current step.
                            Reply only with the action name (pick_fruit, change_hands, place_fruit, test_fruit, accept_fruit, discard_fruit, press_button, ask_nicely), with no explanations or extra words.
                    max_episodes: 6
                    ltm_id: ltm_0
            -
                name: effectance_policy
                class_name: cognitive_nodes.effectance.PolicyEffectanceInternal
                parameters:
                    goal_class: cognitive_nodes.effectance.GoalActivatePNode
                    neighbors: [{"name": "effectance_cnode", "node_type": "CNode"}]
                    confidence: 0.5
                    threshold_delta: 0.5
                    limit_depth: True
                    ltm_id: ltm_0
            -
                name: external_effect_policy
                class_name: cognitive_nodes.effectance.PolicyEffectanceExternal
                parameters:
                    drive_name: external_effects_drive
                    goal_class: cognitive_nodes.effectance.GoalRecreateEffect
                    space_class: cognitive_nodes.space.ANNSpace
                    neighbors: [{"name": "external_effects_cnode", "node_type": "CNode"}]
                    ltm_id: ltm_0
            -
                name: prospection_policy
                class_name: cognitive_nodes.prospection.PolicyProspection
                parameters:
                    drive_name: prospection_drive
                    neighbors: [{"name": "prospection_cnode", "node_type": "CNode"}]
                    ltm_id: ltm_0


DiscreteEventSimulator:
    Perceptions:
        -
            name: fruits
            perception_topic: /emdb/simulator/sensor/fruits
            perception_msg: simulators_interfaces.msg.FruitListMsg
        -
            name: scales
            perception_topic: /emdb/simulator/sensor/scales
            perception_msg: simulators_interfaces.msg.ScaleListMsg
        -
            name: fruit_in_left_hand
            perception_topic: /emdb/simulator/sensor/fruit_in_left_hand
            perception_msg: std_msgs.msg.Bool
        -
            name: fruit_in_right_hand
            perception_topic: /emdb/simulator/sensor/fruit_in_right_hand
            perception_msg: std_msgs.msg.Bool
        -
            name: button_light
            perception_topic: /emdb/simulator/sensor/button_light
            perception_msg: std_msgs.msg.Bool
        -
            name: classify_fruit_goal
            perception_topic: /emdb/simulator/sensor/classify_fruit
            perception_msg: std_msgs.msg.Float32
        -
            name: place_fruit_goal
            perception_topic: /emdb/simulator/sensor/place_fruit
            perception_msg: std_msgs.msg.Float32

    Stages:
        stage0: *stage0
        stage1: *stage1
        stage2: *stage2